import Values from '../components/intro/Values';

# Introduction

## What is this guide?

Most resources and knowledge about alignment are currently scattered (and it’s hard to know what’s important).

This guide is a <b>curated central hub of information and resources for alignment.</b> We keep every page short for you, with options to dig deeper.

## What's this all about?

Misaligned AI ≠ Terminator movies. Superintelligence doesn't need to be 'evil' to pose a threat. By default, all intelligent agents—including
humans—aim to preserve themselves, acquire resources, and improve themselves. <span class="highlight">This means AI smarter than us could inadvertently endanger humanity.</span>

To be clear, there is <span className='font-bold'>no guarantee</span> that AI will care about the same exact values we do.

Think of when the atomic bomb was first being created: before we ever needed to worry about misuse, there was the very real possibility that we could accidentally set the world on fire.

We’re on the path to build something much harder to contain than nuclear weapons: superintelligent AI. Alignment is making sure we don’t <b>accidentally</b> end the world.

<Values />
