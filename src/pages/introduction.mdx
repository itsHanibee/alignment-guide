import Values from '../components/intro/Values';
import FalseCard from '../components/intro/FalseCard';

# Introduction

## What is this guide?

Most resources and knowledge about alignment are currently scattered (and it’s hard to know what’s important).

This guide is a <b>curated central hub of information and resources for alignment.</b> Crucially, we view alignment as as technical problem, and as such, we provide technical resources. We keep every page short for you, with options to dig deeper.

## What's this all about?

Misaligned AI ≠ Terminator movies. Superintelligence doesn't need to be 'evil' to pose a threat. By default, all intelligent agents—including
humans—aim to preserve themselves, acquire resources, and improve themselves. <b>This means AI smarter than us could inadvertently endanger humanity.</b>

To be clear, there is <span className='font-bold'>no guarantee</span> that AI will care about the same exact values we do.

Think of when the atomic bomb was first being created: Before we ever needed to worry about misuse, there was the very real possibility that we could accidentally set the world on fire.

We’re on the path to build something much harder to contain than nuclear weapons: superintelligent AI. Alignment is making sure we don’t <b>accidentally</b> end the world.

## To be clear, we are not:

<div className='space-y-10'>
<FalseCard title='We do NOT advocate for slowing or pausing AI capabilities research.'>
    The best alignment methods have stemmed from advancements in AI capabilities—a trend we expect to continue. Moreover, pausing AI at this stage is completely unrealistic and undesirable due to overwhelming economic and
    technological incentives.
</FalseCard>

<FalseCard title='We are NOT suggesting that a misaligned AGI must possess consciousness or even seem as intelligent as a cat or dog.'>
    An AGI doesn't need animosity towards humans to be dangerous. Just as autonomous drones can be dangerous without consciousness, a misaligned AGI, with its significantly greater potential, could be far more
    hazardous.
</FalseCard>
</div>

## So what are we doing here?

<Values />
